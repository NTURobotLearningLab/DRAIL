<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="DRAIL is a novel adversarial imitation learning framework that integrates a diffusion model into generative adversarial imitation learning..">
  <meta name="keywords" content="Imitation Learning, Adversarial Imitation Learning, Diffusion Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Diffusion-Reward Adversarial Imitation Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Diffusion-Reward Adversarial Imitation Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.mecoli.net/">Chun-Mao Lai</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hsiangchun0205.github.io/">Hsiang-Chun Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://pinghsieh.github.io/">Ping-Chun Hsieh</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://vllab.ee.ntu.edu.tw/ycwang.html">Yu-Chiang Frank Wang</a><sup>1,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://minhungchen.netlify.app/">Min-Hung Chen</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://shaohua0116.github.io/">Shao-Hua Sun</a><sup>1</sup>,
            </span>
            <!-- <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National Taiwan University,</span>
            <span class="author-block"><sup>2</sup>National Yang Ming Chiao Tung University</span>
            <span class="author-block"><sup>3</sup>NVIDIA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.16194"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.16194"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Mecoli1219/DRAIL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning aims to learn a policy from observing expert demonstrations without access to reward signals from environments. Generative adversarial imitation learning (GAIL) formulates imitation learning as adversarial learning, employing a generator policy learning to imitate expert behaviors and discriminator learning to distinguish the expert demonstrations from agent trajectories. Despite its encouraging results, GAIL training is often brittle and unstable. Inspired by the recent dominance of diffusion models in generative modeling, we propose DiffusionReward Adversarial Imitation Learning (DRAIL), which integrates a diffusion model into GAIL, aiming to yield more robust and smoother rewards for policy learning. Specifically, we propose a diffusion discriminative classifier to construct an enhanced discriminator, and design diffusion rewards based on the classifier’s output for policy learning. Extensive experiments are conducted in navigation, manipulation, and locomotion, verifying DRAIL’s effectiveness compared to prior imitation learning methods. Moreover, additional experimental results demonstrate the generalizability and data efficiency of DRAIL. Visualized learned reward functions of GAIL and DRAIL suggest that DRAIL can produce more robust and smoother rewards.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <h2 class="title is-3">Framework Overview</h2>
            </div>
            <div class="content has-text-centered">
              <img src="./static/images/drail_model_fig.pdf" alt="Re-rendered viewpoint" width="75%">
            </div>
            <div class="content has-text-justified">
              <p>
                Our proposed framework DRAIL incorporates a diffusion model into GAIL.
                <strong>(a)</strong>
                Our proposed diffusion discriminative classifier \(D_\phi\) learns to distinguish expert data \((\mathbf{s}_E, \mathbf{a}_E) \sim \tau_E\) from agent data \((\mathbf{s}_\pi, \mathbf{a}_pi) \sim \tau_i\) using a diffusion model. \(D_\phi\) is trained to predict a value closer to \(1\) when the input state-action pairs are sampled from expert demonstration and predict a value closer to \(0\) otherwise.
                <strong>(b)</strong> 
                The policy \(\pi_\theta\) learns to maximize the diffusion reward \(r_\phi\) computed based on the output of \(D_\phi\) that takes the state-action pairs from the policy as input. The closer the policy resembles expert behaviors, the higher the rewards it can obtain.
              </p>
            </div>
          </div>
        </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="columns is-centered">
          <div class="column is-full-width">
            <div class="content has-text-justified">
              <h2 class="title is-3">Framework Overview</h2>
            </div>
            <div class="content has-text-centered">
              <img src="./static/images/env.jpg" alt="Environment Overview" width="75%">
            </div>
            <div class="content has-text-justified">
              <p>(a) <b>Maze:</b>  point-mass agent (<span style="color: green;">green</span>) within a 2D maze is trained to move from its initial position to reach the goal (<span style="color: red;">red</span>).</p>
              <p>(b) <b>FetchPush:</b> The manipulation task is implemented with a 7-DoF Fetch robotics arm. FETCHPUSH requires picking up or pushing an object to a target location (<span style="color: red;">red</span>).</p>
              <p>(c) <b>HandRotate:</b> This dexterous manipulation task requires a Shadow Dexterous Hand to in-hand rotate a block to a target orientation.</p>
              <p>(d) <b>AntReach:</b> This task trains a quadruped ant to reach a goal randomly positioned along the perimeter of a half-circle with a radius of 5 m.</p>
              <p>(e) <b>Walker:</b> This locomotion task requires training a bipedal walker policy to achieve the highest possible walking speed while maintaining balance.</p>
              <p>(f) <b>CarRacing:</b> This image-based racing game task requires driving a car to navigate a track as quickly as possible.</p>
            </div>
          </div>
        </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <h2 class="title is-3">Learning Efficiency</h2>
            <p>
              We report success rates (Maze, FetchPush, HandRotate, AntReach) and return (Walker, CarRacing), evaluated over five random seeds. Our method DRAIL learns more stably, faster, and achieves higher or competitive performance compared to the best-performing baseline in all the tasks.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/learning_efficiency.jpg" alt="Re-rendered viewpoint" width="75%">
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <h2 class="title is-3">Generalization Experiments in FetchPush</h2>
            <p>
              We present the performance of our proposed DRAIL and baselines in the FETCHPUSH task, under varying levels of noise in initial states and goal locations. The evaluation spans three random seeds, and the training curve illustrates the success rate dynamics.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/generalization_experiments.jpg" alt="Re-rendered viewpoint" width="75%">
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <h2 class="title is-3">Data Efficiency</h2>
            <p>
              We experiment learning with varying amounts of expert data in Walker and FetchPush. The results show that our proposed method DRAIL is more data efficient, i.e., can learn with less expert data, compared to other methods.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/data_efficiency.jpg" alt="Re-rendered viewpoint" width="75%">
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">
            <h2 class="title is-3">Reward Function Visualization</h2>
            <p>
              We present visualizations of the learned reward values by the discriminative classifier of GAIL and the diffusion discriminative classifier of our DRAIL. The target expert demonstration for imitation is depicted in (a), which is a discontinuous sine function. The reward distributions of GAIL and our DRAIL are illustrated in (b) and (c), respectively.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/reward_function.jpg" alt="Re-rendered viewpoint" width="75%">
          </div>
        </div>
      </div>

    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{lai2024diffusion,
  title     = {Diffusion-Reward Adversarial Imitation Learning},
  author    = {Chun-Mao Lai, Hsiang-Chun Wang, Ping-Chun Hsieh, Yu-Chiang Frank Wang, Min-Hung Chen, Shao-Hua Sun},
  journal   = {arXiv preprint arXiv:2405.16194},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
